{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Desafío 2\n",
        "\n",
        "* Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
        "* Probar términos de interés y explicar similitudes en el espacio de embeddings.\n",
        "* Intentar plantear y probar tests de analogías.\n",
        "* Graficar los embeddings resultantes.\n",
        "* Obtener conclusiones."
      ],
      "metadata": {
        "id": "fcqo7l_zcCtN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f7DhsIQNZzRU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a utilizar el dataset movie_reviews de nltk, que contiene 2000 reseñas de películas que fueron extraídas de la página web IMDb."
      ],
      "metadata": {
        "id": "LOgjgKnNgg6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "nltk.download('movie_reviews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUkKxg2yfEnN",
        "outputId": "b6b7339a-f250-4dce-98f5-d5c9619d2216"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creo una lista vacía para almacenar todas las palabras\n",
        "sentence_tokens = []\n",
        "\n",
        "# Recorro todas las reseñas en el dataset\n",
        "for fileid in movie_reviews.fileids():\n",
        "    # Extraigo las palabras de cada reseña\n",
        "    words_in_review = movie_reviews.words(fileid)\n",
        "    # Agrego las palabras a la lista all_words\n",
        "    sentence_tokens.append(words_in_review)\n",
        "\n",
        "print(sentence_tokens[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wj195zhOf5DC",
        "outputId": "dd824cc4-a458-46fd-bfa8-6d399f77e355"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...], ['the', 'happy', 'bastard', \"'\", 's', 'quick', 'movie', ...]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos los vectores (word2vec)"
      ],
      "metadata": {
        "id": "4UA2HDhJfh6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobrecargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ],
      "metadata": {
        "id": "z_2grE-FflSn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos el modelo generador de vectores\n",
        "# En este caso utilizaremos la estructura modelo Skipgram\n",
        "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=1)           # modelo 0:CBOW  1:skipgram"
      ],
      "metadata": {
        "id": "BDXkxA3Vfsdh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener el vocabulario con los tokens\n",
        "w2v_model.build_vocab(sentence_tokens)"
      ],
      "metadata": {
        "id": "uvPjPaIzfyfA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de filas/docs encontradas en el corpus\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz9ACZXUhb6G",
        "outputId": "1e30056f-5334-4c3c-bd8c-813f5b1d8833"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de words encontradas en el corpus\n",
        "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BBR6ly5hhb3",
        "outputId": "75479ea5-65b1-422e-dc1d-65d03c8cecc4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de words distintas en el corpus: 14794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenar embeddings"
      ],
      "metadata": {
        "id": "N2cWCWn7iBVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model.train(sentence_tokens,\n",
        "                 total_examples=w2v_model.corpus_count,\n",
        "                 epochs=20,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVYFBNvriDL_",
        "outputId": "eb77e5c3-f13f-4e7b-d487-e59d940174bb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 10556760.0\n",
            "Loss after epoch 1: 8665212.0\n",
            "Loss after epoch 2: 8417764.0\n",
            "Loss after epoch 3: 8539596.0\n",
            "Loss after epoch 4: 8979728.0\n",
            "Loss after epoch 5: 8781440.0\n",
            "Loss after epoch 6: 8602080.0\n",
            "Loss after epoch 7: 5340884.0\n",
            "Loss after epoch 8: 1686856.0\n",
            "Loss after epoch 9: 1657480.0\n",
            "Loss after epoch 10: 1629336.0\n",
            "Loss after epoch 11: 1593248.0\n",
            "Loss after epoch 12: 1555280.0\n",
            "Loss after epoch 13: 1517816.0\n",
            "Loss after epoch 14: 1475352.0\n",
            "Loss after epoch 15: 1434008.0\n",
            "Loss after epoch 16: 1389584.0\n",
            "Loss after epoch 17: 1351200.0\n",
            "Loss after epoch 18: 1313784.0\n",
            "Loss after epoch 19: 1281280.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21528686, 31676400)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensayar embeddings"
      ],
      "metadata": {
        "id": "MznmwUDKsKkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_similarity(word, model, top_n):\n",
        "  print(\"Palabras que más se relacionan:\")\n",
        "  for i in model.wv.most_similar(positive=[word], topn=top_n):\n",
        "    print(f\"- {i}\")\n",
        "  print(\"\\nPalabras que menos se relacionan:\")\n",
        "  for i in model.wv.most_similar(negative=[word], topn=top_n):\n",
        "    print(f\"- {i}\")"
      ],
      "metadata": {
        "id": "oQa_dlNewMDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_similarity(\"excellent\", w2v_model, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-0M0n3rsOC2",
        "outputId": "fe57cb6d-3260-4249-c11d-a549b77e0bc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que más se relacionan:\n",
            "- ('exceptional', 0.5097795128822327)\n",
            "- ('serviceable', 0.5081827044487)\n",
            "- ('phenomenal', 0.49987083673477173)\n",
            "- ('admirable', 0.4943481683731079)\n",
            "- ('commendable', 0.49249696731567383)\n",
            "- ('splendid', 0.47906795144081116)\n",
            "- ('anemic', 0.47830644249916077)\n",
            "- ('outstanding', 0.47467321157455444)\n",
            "- ('adequate', 0.4624604880809784)\n",
            "- ('marvellous', 0.4550897777080536)\n",
            "\n",
            "Palabras que menos se relacionan:\n",
            "- ('studio', 0.060081787407398224)\n",
            "- ('emperor', 0.016611145809292793)\n",
            "- ('psychological', 0.016446737572550774)\n",
            "- ('free', 0.016072148457169533)\n",
            "- ('station', 0.010540219023823738)\n",
            "- ('remote', 0.009976881556212902)\n",
            "- ('bus', 0.009528594091534615)\n",
            "- ('volcano', 0.009369288571178913)\n",
            "- ('become', 0.006655802484601736)\n",
            "- ('shadows', 0.006197808310389519)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Palabras más similares: La mayoría de las palabras relacionadas con \"excellent\" son sinónimos o términos que expresan cualidades positivas, como \"exceptional\", \"phenomenal\", y \"outstanding\". Esto sugiere que el modelo capta bien las asociaciones positivas.\n",
        "* Palabras menos similares: Las palabras como \"studio\", \"emperor\", y \"psychological\" son términos más técnicos o específicos, que no están directamente relacionados con la cualidad de ser \"excelente\". Esto indica que el modelo también puede identificar correctamente términos que no comparten similitud semántica con \"excellent\"."
      ],
      "metadata": {
        "id": "3fo_4NLjzOua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_similarity(\"boring\", w2v_model, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWTX3dbMuXhd",
        "outputId": "2b24470a-533f-4427-9641-94daa00c5b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que más se relacionan:\n",
            "- ('trite', 0.4752159118652344)\n",
            "- ('uninvolving', 0.4743850827217102)\n",
            "- ('repetitive', 0.4715314507484436)\n",
            "- ('unentertaining', 0.47124287486076355)\n",
            "- ('sluggish', 0.4603671431541443)\n",
            "- ('mushy', 0.4571177661418915)\n",
            "- ('unengaging', 0.4563826620578766)\n",
            "- ('unrealistic', 0.44881296157836914)\n",
            "- ('incoherent', 0.44725513458251953)\n",
            "- ('predictable', 0.4434445798397064)\n",
            "\n",
            "Palabras que menos se relacionan:\n",
            "- ('quest', 0.05052599683403969)\n",
            "- ('official', 0.04224354773759842)\n",
            "- ('cuba', 0.03665873780846596)\n",
            "- ('wave', 0.027178825810551643)\n",
            "- ('operations', 0.013799885287880898)\n",
            "- ('wounds', 0.010254197753965855)\n",
            "- ('federal', 0.008846511133015156)\n",
            "- ('catholic', 0.00584804592654109)\n",
            "- ('jan', 0.0015884280437603593)\n",
            "- ('newly', 0.0012582188937813044)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Palabras más similares: Los términos relacionados como \"trite\", \"uninvolving\", y \"unentertaining\" son todos sinónimos de aburrido o términos que expresan una falta de interés, lo cual es coherente. Esto demuestra que el modelo puede identificar bien los términos negativos asociados con \"boring\".\n",
        "* Palabras menos similares: Los términos como \"quest\", \"official\", y \"cuba\" no tienen relación directa con \"boring\". Son términos más neutrales o que describen conceptos específicos, lo que refuerza la idea de que el modelo distingue bien entre términos que no están relacionados con el aburrimiento."
      ],
      "metadata": {
        "id": "q4qyEYBZzh0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_similarity(\"plot\", w2v_model, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF5eG2spvk5k",
        "outputId": "7c070cd2-f5ed-4261-8484-56f6c9e622b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que más se relacionan:\n",
            "- ('plotline', 0.4470919966697693)\n",
            "- ('framework', 0.44570252299308777)\n",
            "- ('gaping', 0.4426176846027374)\n",
            "- ('narrative', 0.4408288598060608)\n",
            "- ('storyline', 0.43191319704055786)\n",
            "- ('thematic', 0.4203898310661316)\n",
            "- ('twists', 0.39642447233200073)\n",
            "- ('holes', 0.3961651027202606)\n",
            "- ('illogical', 0.39569684863090515)\n",
            "- ('storylines', 0.394579142332077)\n",
            "\n",
            "Palabras que menos se relacionan:\n",
            "- ('loves', 0.04487187787890434)\n",
            "- ('bank', 0.01958320662379265)\n",
            "- ('beverly', 0.011829300783574581)\n",
            "- ('owns', 0.00719066709280014)\n",
            "- ('exec', 0.006814504973590374)\n",
            "- ('husbands', 0.0035288440994918346)\n",
            "- ('thief', 0.0021198061294853687)\n",
            "- ('died', 0.0012220180360600352)\n",
            "- ('meets', -0.0004237558168824762)\n",
            "- ('capture', -0.002436400391161442)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Palabras más similares: Las palabras más similares, como \"plotline\", \"narrative\", y \"storyline\", son claramente términos relacionados con la trama de una película, lo que muestra que el modelo entiende bien los conceptos relacionados con \"plot\".\n",
        "* Palabras menos similares: Los términos menos relacionados, como \"loves\", \"bank\", y \"beverly\", son términos que describen acciones, lugares, o personas que no están intrínsecamente conectados con la estructura de una trama, lo que nuevamente demuestra que el modelo distingue correctamente los conceptos."
      ],
      "metadata": {
        "id": "OvRAJPMUzscf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_similarity(\"soundtrack\", w2v_model, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LYau_2avu5g",
        "outputId": "a8474f6f-5325-40a0-c176-bb11a00b9826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que más se relacionan:\n",
            "- ('blaring', 0.4737194776535034)\n",
            "- ('songs', 0.4671975076198578)\n",
            "- ('bombastic', 0.4514937996864319)\n",
            "- ('vocals', 0.45014312863349915)\n",
            "- ('tunes', 0.4415893256664276)\n",
            "- ('catchy', 0.4350740611553192)\n",
            "- ('music', 0.43315520882606506)\n",
            "- ('prominently', 0.4327533543109894)\n",
            "- ('evocative', 0.4313206076622009)\n",
            "- ('composed', 0.42703986167907715)\n",
            "\n",
            "Palabras que menos se relacionan:\n",
            "- ('seeking', 0.111798495054245)\n",
            "- ('prove', 0.08031805604696274)\n",
            "- ('control', 0.07057682424783707)\n",
            "- ('selfish', 0.053177326917648315)\n",
            "- ('thinks', 0.048465486615896225)\n",
            "- ('hero', 0.04393875226378441)\n",
            "- ('maximus', 0.041020091623067856)\n",
            "- ('existence', 0.0376749187707901)\n",
            "- ('commits', 0.03345293551683426)\n",
            "- ('profession', 0.033451441675424576)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Palabras más similares: Las palabras más relacionadas con \"soundtrack\" incluyen términos como \"blaring,\" \"songs,\" \"bombastic,\" y \"vocals,\" que están fuertemente asociados con elementos musicales y sonoros, lo cual es lógico dado que un \"soundtrack\" se refiere a la música de una película o producción audiovisual.\n",
        "* Palabras menos similares: Las palabras menos relacionadas incluyen términos como \"seeking,\" \"prove,\" \"control,\" y \"selfish,\" que están más asociados con conceptos abstractos, comportamientos humanos, y roles en una narrativa, los cuales no están directamente conectados con el concepto de una banda sonora."
      ],
      "metadata": {
        "id": "JEpyNxrh0sUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_similarity(\"director\", w2v_model, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XweUK7tUv0ZA",
        "outputId": "6fd339a4-1345-47e3-cdae-3d1ca47627c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que más se relacionan:\n",
            "- ('silvio', 0.4229823052883148)\n",
            "- ('screenwriter', 0.4168570041656494)\n",
            "- ('auteur', 0.410645067691803)\n",
            "- ('mostow', 0.40190473198890686)\n",
            "- ('maker', 0.398929625749588)\n",
            "- ('harlin', 0.39684581756591797)\n",
            "- ('composer', 0.39665651321411133)\n",
            "- ('helmer', 0.39663732051849365)\n",
            "- ('abrahams', 0.39433541893959045)\n",
            "- ('directors', 0.39396676421165466)\n",
            "\n",
            "Palabras que menos se relacionan:\n",
            "- ('sexual', 0.06964030861854553)\n",
            "- ('legs', 0.05164989456534386)\n",
            "- ('plant', 0.03904620185494423)\n",
            "- ('desert', 0.035672351717948914)\n",
            "- ('beyond', 0.03022555075585842)\n",
            "- ('against', 0.02431575581431389)\n",
            "- ('bitter', 0.019635997712612152)\n",
            "- ('important', 0.01725214719772339)\n",
            "- ('eyes', 0.015954824164509773)\n",
            "- ('game', 0.014953896403312683)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Palabras más similares: Palabras como \"screenwriter\", \"auteur\", y \"maker\" están todas relacionadas con roles en la producción de una película, lo que indica que el modelo comprende el contexto de \"director\".\n",
        "* Palabras menos similares: Términos como \"sexual\", \"legs\", y \"desert\" no están directamente relacionados con el papel de un director, lo que sugiere que el modelo sabe diferenciar entre términos de producción cinematográfica y otros conceptos más generales o específicos."
      ],
      "metadata": {
        "id": "Nt6x-BToz9N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_similarity(\"actor\", w2v_model, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xiOU2eYyTAH",
        "outputId": "4f7906bc-6226-4c75-a850-b8741975e433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palabras que más se relacionan:\n",
            "- ('actress', 0.46144258975982666)\n",
            "- ('actors', 0.4312831163406372)\n",
            "- ('thespian', 0.4283738434314728)\n",
            "- ('comedian', 0.4277372360229492)\n",
            "- ('performers', 0.4161418378353119)\n",
            "- ('berenger', 0.41306445002555847)\n",
            "- ('versatile', 0.40391314029693604)\n",
            "- ('rochon', 0.4017593264579773)\n",
            "- ('hack', 0.3986037075519562)\n",
            "- ('prodigy', 0.3983077108860016)\n",
            "\n",
            "Palabras que menos se relacionan:\n",
            "- ('animals', 0.05294450744986534)\n",
            "- ('run', 0.0525544211268425)\n",
            "- ('mystical', 0.03184853866696358)\n",
            "- ('cloud', 0.031199902296066284)\n",
            "- ('soaked', 0.030755585059523582)\n",
            "- ('boiling', 0.030244749039411545)\n",
            "- ('ritual', 0.02562571130692959)\n",
            "- ('mulder', 0.02559625171124935)\n",
            "- ('gruesome', 0.022487064823508263)\n",
            "- ('report', 0.021151980385184288)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Palabras más similares: Las palabras más relacionadas con \"actor\" incluyen \"actress\", \"actors\", \" y \"comedian\" que son directamente relevantes al término, indicando roles o sinónimos dentro de la actuación y el cine.\n",
        "* Palabras menos similares: Las palabras menos relacionadas incluyen términos como \"animals\", \"run\", \"mystical\" y \"cloud\" que no tienen una conexión directa con la profesión o el concepto de un actor, siendo más abstractos o relacionados con contextos completamente diferentes."
      ],
      "metadata": {
        "id": "Lbfvwhd609To"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos un test de analogía\n",
        "def analogy_test(model, A, B, C):\n",
        "\n",
        "  # D_pred = embedding(B) − embedding(A) + embedding(C)\n",
        "  D_pred = model.wv.most_similar(positive=[B, C], negative=[A], topn=1)\n",
        "\n",
        "  print(f\"{A} es a {B} como {C} es a {D_pred[0][0]}\")"
      ],
      "metadata": {
        "id": "xiR9FTIuQ3ju"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analogy_test(w2v_model, \"man\", \"woman\", \"actor\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaIr_KT_VFRN",
        "outputId": "21680985-c7ab-447f-c974-df7a27519024"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "man es a woman como actor es a actress\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analogy_test(w2v_model, \"good\", \"bad\", \"entertaining\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s142AksVRdj",
        "outputId": "c666af49-455d-4162-a96e-f701548d92c9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "good es a bad como entertaining es a insipid\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- La relación entre man y woman es análoga a la de actor y actress, lo que muestra que el modelo de embeddings es capaz de capturar correctamente relaciones de género en diferentes contextos.\n",
        "\n",
        "- La relación entre good y bad como opuestos se refleja de manera adecuada en la relación entre entertaining y insipid. Aquí, el modelo ha captado que insipido es lo contrario de entretenido.\n",
        "\n",
        "En resumen, el modelo de embeddings parece funcionar bien para capturar relaciones semánticas como género y opuestos, demostrando su capacidad para identificar analogías en diferentes contextos de lenguaje. Esto sugiere que el modelo está bien entrenado en aspectos fundamentales del lenguaje como roles y valoraciones."
      ],
      "metadata": {
        "id": "he-MuaVGWHp9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graficar los embeddings"
      ],
      "metadata": {
        "id": "i00RAMn71oDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def reduce_dimensions(model, num_dimensions = 2 ):\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index_to_key)\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    return vectors, labels"
      ],
      "metadata": {
        "id": "-8fFDePC18H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "vecs, labels = reduce_dimensions(w2v_model)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "FYBgYUF01_NZ",
        "outputId": "abe0ecdf-8bbd-4b28-b90e-7d126d795878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f95bf40e-4052-4824-be0a-b87c8118b58f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f95bf40e-4052-4824-be0a-b87c8118b58f\")) {                    Plotly.newPlot(                        \"f95bf40e-4052-4824-be0a-b87c8118b58f\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\",\",\"the\",\".\",\"a\",\"and\",\"of\",\"to\",\"'\",\"is\",\"in\",\"s\",\"\\\"\",\"it\",\"that\",\"-\",\")\",\"(\",\"as\",\"with\",\"for\",\"his\",\"this\",\"film\",\"i\",\"he\",\"but\",\"on\",\"are\",\"t\",\"by\",\"be\",\"one\",\"movie\",\"an\",\"who\",\"not\",\"you\",\"from\",\"at\",\"was\",\"have\",\"they\",\"has\",\"her\",\"all\",\"?\",\"there\",\"like\",\"so\",\"out\",\"about\",\"up\",\"more\",\"what\",\"when\",\"which\",\"or\",\"she\",\"their\",\":\",\"some\",\"just\",\"can\",\"if\",\"we\",\"him\",\"into\",\"even\",\"only\",\"than\",\"no\",\"time\",\"good\",\"most\",\"its\",\"will\",\"story\",\"would\",\"been\",\"much\",\"character\",\"also\",\"get\",\"other\",\"do\",\"two\",\"well\",\"them\",\"very\",\"characters\",\";\",\"first\",\"--\",\"after\",\"see\",\"!\",\"way\",\"because\",\"make\",\"life\",\"off\",\"too\",\"any\",\"does\",\"really\",\"had\",\"while\",\"films\",\"how\",\"plot\",\"little\",\"where\",\"people\",\"over\",\"could\",\"then\",\"me\",\"scene\",\"man\",\"bad\",\"my\",\"never\",\"being\",\"best\",\"these\",\"don\",\"new\",\"doesn\",\"scenes\",\"many\",\"director\",\"such\",\"know\",\"were\",\"movies\",\"through\",\"here\",\"action\",\"great\",\"re\",\"another\",\"love\",\"go\",\"made\",\"us\",\"big\",\"end\",\"something\",\"back\",\"*\",\"still\",\"world\",\"seems\",\"work\",\"those\",\"makes\",\"now\",\"before\",\"however\",\"between\",\"few\",\"\\u002f\",\"down\",\"every\",\"though\",\"better\",\"real\",\"audience\",\"enough\",\"seen\",\"take\",\"around\",\"both\",\"going\",\"year\",\"performance\",\"why\",\"role\",\"should\",\"isn\",\"same\",\"old\",\"gets\",\"your\",\"may\",\"things\",\"think\",\"years\",\"last\",\"comedy\",\"funny\",\"actually\",\"ve\",\"long\",\"look\",\"almost\",\"own\",\"thing\",\"fact\",\"nothing\"],\"x\":[-16.262371063232422,7.592073917388916,-16.262882232666016,-3.9391350746154785,-16.23735237121582,12.543400764465332,-5.640533924102783,-16.855876922607422,2.3633792400360107,-6.101795673370361,-17.146484375,-20.90704345703125,-4.253601551055908,23.16206932067871,-1.482414722442627,-14.28299617767334,-13.444147109985352,4.5125017166137695,19.32142448425293,-3.7861714363098145,15.005266189575195,-5.0220465660095215,-6.514516353607178,-11.967891693115234,-26.388940811157227,4.5169477462768555,-33.18645095825195,-1.453513503074646,-7.241866111755371,-2.307563304901123,-7.575189113616943,-7.372855186462402,-15.958986282348633,4.849571704864502,-7.5785346031188965,-5.291402816772461,-4.680845260620117,-11.52542495727539,7.545688152313232,-15.61888313293457,-9.025222778320312,-7.200872898101807,-6.196169853210449,9.307890892028809,11.68515396118164,-17.25092315673828,-3.1816396713256836,-19.24844741821289,-4.228060722351074,25.361835479736328,-3.570862293243408,20.680173873901367,-8.218925476074219,-3.404320478439331,27.434284210205078,24.252201080322266,-1.8331491947174072,3.0253851413726807,15.056706428527832,-34.86540222167969,9.883214950561523,-2.2251944541931152,-38.76677703857422,-13.095513343811035,-7.203121662139893,23.285499572753906,20.245399475097656,-3.9395370483398438,-29.384836196899414,-9.287617683410645,-2.921774387359619,17.3333797454834,-5.561548233032227,-8.474324226379395,-1.0766476392745972,-0.840337336063385,6.032341957092285,-9.664383888244629,-11.119417190551758,-7.1408209800720215,-7.3065667152404785,-19.58277130126953,-5.616299152374268,9.879222869873047,-7.380514144897461,26.26059913635254,-15.330282211303711,-0.6702168583869934,-10.832321166992188,-1.0316606760025024,-16.56676483154297,-15.42617130279541,-1.7445305585861206,25.393260955810547,-8.385295867919922,-14.882566452026367,27.77017593383789,34.96403503417969,-5.747335433959961,14.938091278076172,29.827186584472656,-3.7659311294555664,10.871793746948242,3.37856125831604,-14.350711822509766,-11.303850173950195,-5.958853244781494,-23.454181671142578,-3.921812057495117,5.4590229988098145,-1.350509762763977,29.28175163269043,11.171682357788086,32.148189544677734,-8.409652709960938,27.449424743652344,-18.85551643371582,23.96034812927246,-2.7764081954956055,-16.871002197265625,-16.844881057739258,-8.018624305725098,1.217324137687683,-8.842849731445312,-7.930569171905518,-39.07699966430664,9.396559715270996,-39.47441101074219,-3.2635319232940674,-19.615625381469727,-29.220348358154297,-9.729010581970215,-9.552046775817871,1.7609617710113525,-24.054771423339844,14.093352317810059,-3.3783557415008545,-19.625394821166992,-18.233299255371094,0.5255277156829834,-20.742122650146484,-1.6538870334625244,27.187328338623047,-12.85332202911377,-18.879236221313477,-15.494043350219727,38.94962692260742,-2.719127893447876,29.189054489135742,-35.530845642089844,-12.258796691894531,7.268047332763672,24.860780715942383,-4.201833248138428,-8.492371559143066,-1.4061508178710938,-12.875539779663086,33.0981559753418,25.288440704345703,10.136990547180176,-27.924989700317383,-19.606473922729492,28.43705940246582,8.48454761505127,2.8289222717285156,-8.51540470123291,-2.0162100791931152,6.619387149810791,-5.745749473571777,36.29969787597656,-4.879642963409424,29.711219787597656,-12.207157135009766,29.523290634155273,-25.220643997192383,-19.80405616760254,-12.478141784667969,-6.908862113952637,-5.307149410247803,-39.711666107177734,1.45289146900177,3.6294422149658203,15.469605445861816,-3.566499948501587,-5.396151542663574,17.774364471435547,-9.834488868713379,-24.06019401550293,-25.271446228027344,-12.635904312133789,-7.192688465118408,-8.666267395019531,-10.934815406799316,-3.1817028522491455,-3.8999764919281006,-16.933191299438477,20.371871948242188,-3.605005979537964,-5.081465244293213,5.773732662200928],\"xaxis\":\"x\",\"y\":[-10.17635440826416,12.840673446655273,-10.161003112792969,16.470073699951172,-10.162642478942871,25.37047576904297,4.92462682723999,-9.333307266235352,26.632606506347656,12.870948791503906,-9.643644332885742,2.368412494659424,7.307795524597168,32.5706672668457,-12.24911117553711,-36.07796096801758,-34.628536224365234,3.990309000015259,5.678203582763672,12.570849418640137,-36.057960510253906,10.958072662353516,11.687024116516113,2.185298442840576,-17.30593490600586,30.074188232421875,17.55072021484375,22.265274047851562,6.134477138519287,-9.909903526306152,10.355031967163086,17.011953353881836,11.61858081817627,-5.487818241119385,-30.211790084838867,26.913352966308594,6.158777713775635,-5.850893020629883,-2.164243221282959,4.859703063964844,3.976980686187744,5.389707088470459,-6.738959312438965,-33.87196350097656,7.191640853881836,-5.767357349395752,15.40607738494873,2.843139886856079,23.443408966064453,2.0858304500579834,9.389047622680664,2.5103750228881836,14.311060905456543,8.817911148071289,13.078948020935059,28.957805633544922,11.940577507019043,-36.18928146362305,-11.67326545715332,-8.900106430053711,6.967939376831055,11.739654541015625,3.476428747177124,-0.8278306126594543,5.436611652374268,-22.23984718322754,0.5779051780700684,28.284605026245117,-20.534059524536133,14.816329956054688,11.798849105834961,11.781840324401855,30.51268768310547,17.442155838012695,18.96700096130371,3.588702917098999,41.37309646606445,8.69118881225586,8.768942832946777,9.668651580810547,-9.63579273223877,37.31171798706055,-4.1197509765625,8.262275695800781,-0.38243865966796875,37.520477294921875,40.73178482055664,14.384055137634277,34.731685638427734,22.881988525390625,-11.195221900939941,10.14052963256836,19.562597274780273,14.794610023498535,-2.388604164123535,-2.6972599029541016,-0.5154086351394653,19.125965118408203,-0.9546740055084229,1.8090542554855347,0.055480729788541794,40.023441314697266,31.704967498779297,21.924057006835938,0.4276711940765381,6.5036187171936035,12.533919334411621,14.498370170593262,3.1807830333709717,37.20066833496094,37.692684173583984,11.719040870666504,-2.201014757156372,-8.180724143981934,5.861222267150879,7.378029823303223,-12.442121505737305,11.675382614135742,-23.009498596191406,37.77452087402344,2.227461338043213,43.43449783325195,24.66305923461914,17.26949691772461,18.85858726501465,2.688498020172119,-26.232177734375,2.86212420463562,23.434627532958984,16.090158462524414,-21.197307586669922,20.236358642578125,1.179740309715271,-2.892040729522705,13.062248229980469,5.242611408233643,15.2004976272583,22.401966094970703,35.22249221801758,8.728147506713867,13.849533081054688,-40.60151290893555,6.728422164916992,11.199856758117676,-12.515186309814453,13.598067283630371,4.815514087677002,9.611639022827148,-7.396456718444824,10.876018524169922,3.9749414920806885,9.451793670654297,25.720535278320312,4.070974349975586,18.32358741760254,14.863993644714355,-1.2065060138702393,8.747451782226562,32.839256286621094,-7.876878261566162,34.591896057128906,-17.610937118530273,-2.010241746902466,8.919998168945312,22.719989776611328,14.250962257385254,14.178912162780762,14.724432945251465,26.051488876342773,16.818702697753906,-0.24158355593681335,-9.584524154663086,23.09795570373535,12.852797508239746,1.1854265928268433,-19.354843139648438,-3.061680316925049,-12.661761283874512,6.266767978668213,3.0310769081115723,15.711372375488281,-22.49472999572754,-23.977567672729492,6.676620960235596,6.541197776794434,17.51649284362793,4.2703633308410645,39.88926696777344,9.864642143249512,26.409120559692383,30.689252853393555,8.200145721435547,3.963942527770996,44.02593994140625,4.628383159637451,22.85940170288086,15.103644371032715,13.91254711151123,10.30608081817627,1.8632718324661255],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f95bf40e-4052-4824-be0a-b87c8118b58f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los embedddings en 3D\n",
        "\n",
        "vecs, labels = reduce_dimensions(w2v_model,3)\n",
        "\n",
        "fig = px.scatter_3d(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], z=vecs[:MAX_WORDS,2],text=labels[:MAX_WORDS])\n",
        "fig.update_traces(marker_size = 2)\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "gA9b56Ju2Dak",
        "outputId": "89e8e785-4559-4ee6-8338-40a9c19cbc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"27b8f9af-19a5-48d4-a1c6-da153bef2aea\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"27b8f9af-19a5-48d4-a1c6-da153bef2aea\")) {                    Plotly.newPlot(                        \"27b8f9af-19a5-48d4-a1c6-da153bef2aea\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"size\":2},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\",\",\"the\",\".\",\"a\",\"and\",\"of\",\"to\",\"'\",\"is\",\"in\",\"s\",\"\\\"\",\"it\",\"that\",\"-\",\")\",\"(\",\"as\",\"with\",\"for\",\"his\",\"this\",\"film\",\"i\",\"he\",\"but\",\"on\",\"are\",\"t\",\"by\",\"be\",\"one\",\"movie\",\"an\",\"who\",\"not\",\"you\",\"from\",\"at\",\"was\",\"have\",\"they\",\"has\",\"her\",\"all\",\"?\",\"there\",\"like\",\"so\",\"out\",\"about\",\"up\",\"more\",\"what\",\"when\",\"which\",\"or\",\"she\",\"their\",\":\",\"some\",\"just\",\"can\",\"if\",\"we\",\"him\",\"into\",\"even\",\"only\",\"than\",\"no\",\"time\",\"good\",\"most\",\"its\",\"will\",\"story\",\"would\",\"been\",\"much\",\"character\",\"also\",\"get\",\"other\",\"do\",\"two\",\"well\",\"them\",\"very\",\"characters\",\";\",\"first\",\"--\",\"after\",\"see\",\"!\",\"way\",\"because\",\"make\",\"life\",\"off\",\"too\",\"any\",\"does\",\"really\",\"had\",\"while\",\"films\",\"how\",\"plot\",\"little\",\"where\",\"people\",\"over\",\"could\",\"then\",\"me\",\"scene\",\"man\",\"bad\",\"my\",\"never\",\"being\",\"best\",\"these\",\"don\",\"new\",\"doesn\",\"scenes\",\"many\",\"director\",\"such\",\"know\",\"were\",\"movies\",\"through\",\"here\",\"action\",\"great\",\"re\",\"another\",\"love\",\"go\",\"made\",\"us\",\"big\",\"end\",\"something\",\"back\",\"*\",\"still\",\"world\",\"seems\",\"work\",\"those\",\"makes\",\"now\",\"before\",\"however\",\"between\",\"few\",\"\\u002f\",\"down\",\"every\",\"though\",\"better\",\"real\",\"audience\",\"enough\",\"seen\",\"take\",\"around\",\"both\",\"going\",\"year\",\"performance\",\"why\",\"role\",\"should\",\"isn\",\"same\",\"old\",\"gets\",\"your\",\"may\",\"things\",\"think\",\"years\",\"last\",\"comedy\",\"funny\",\"actually\",\"ve\",\"long\",\"look\",\"almost\",\"own\",\"thing\",\"fact\",\"nothing\"],\"x\":[-34.990177154541016,-23.567468643188477,-35.62615966796875,-22.035860061645508,-33.395286560058594,7.4251532554626465,53.09602355957031,-48.92697525024414,18.777233123779297,-19.969467163085938,-50.02295684814453,-11.77922248840332,22.642295837402344,19.900314331054688,-20.19455909729004,-27.72007179260254,-26.492477416992188,-33.74597930908203,25.959726333618164,49.17844009399414,5.670803546905518,10.686866760253906,7.967750072479248,-18.45530128479004,-47.77961730957031,-5.530506134033203,52.29767990112305,5.3084716796875,-7.32362174987793,-29.075395584106445,9.803281784057617,-9.628811836242676,7.864734649658203,-38.382423400878906,-12.988309860229492,4.033026218414307,24.826885223388672,57.8936882019043,26.16120147705078,-46.30027770996094,35.974483489990234,29.905155181884766,-29.938499450683594,15.448970794677734,18.41037940979004,-43.533103942871094,15.995686531066895,-13.24570369720459,5.280267715454102,44.35695266723633,18.44757080078125,15.268495559692383,11.885154724121094,19.0678653717041,56.3522834777832,-18.275188446044922,-14.95659065246582,4.854214668273926,8.129847526550293,-24.560705184936523,16.980018615722656,21.02886199951172,2.6319291591644287,-48.355342864990234,27.04572105407715,43.277191162109375,11.714801788330078,0.3918769657611847,-54.225318908691406,10.98292350769043,13.641680717468262,8.198442459106445,-32.324867248535156,-12.825175285339355,6.700077533721924,38.741615295410156,-7.84550666809082,28.067707061767578,11.219767570495605,8.512813568115234,-6.488040447235107,-12.406261444091797,42.10322952270508,24.152803421020508,35.159202575683594,-12.6266508102417,-36.55673599243164,18.571258544921875,-20.140867233276367,6.446533203125,-36.61383819580078,4.398602485656738,35.253257751464844,6.983407497406006,30.95010757446289,-37.73166275024414,54.16875076293945,17.70020866394043,39.74697494506836,38.58143615722656,13.986355781555176,-1.1480076313018799,27.021102905273438,29.420608520507812,29.528474807739258,19.847633361816406,9.65063190460205,-19.131858825683594,19.321279525756836,16.998579025268555,5.778402328491211,-2.765608787536621,16.59184455871582,34.311729431152344,27.54366111755371,30.197158813476562,-43.31836700439453,-2.4536421298980713,-1.7749117612838745,11.237751960754395,-1.3836486339569092,-6.698520183563232,5.693332195281982,-15.532523155212402,-14.84252643585205,2.2260470390319824,1.8561391830444336,-1.7549277544021606,1.510799527168274,-16.75645637512207,-52.559913635253906,-35.1193962097168,32.234153747558594,-29.19814682006836,-20.866111755371094,58.007320404052734,13.254044532775879,-12.884632110595703,-36.59540939331055,17.213836669921875,-23.956674575805664,1.357900857925415,34.284324645996094,-6.756725788116455,-41.197547912597656,56.82842254638672,27.42214584350586,17.998611450195312,30.363534927368164,-16.543197631835938,20.965023040771484,37.070106506347656,43.75147247314453,32.72298049926758,-11.69138240814209,21.992111206054688,-39.76652908325195,2.940535068511963,24.870494842529297,-12.417571067810059,-13.586060523986816,-31.56014060974121,10.160805702209473,-4.640935897827148,28.301010131835938,7.6046462059021,28.872554779052734,10.823956489562988,23.80220603942871,5.988345146179199,33.89223861694336,41.41679763793945,-21.832141876220703,13.327811241149902,-14.083459854125977,-43.074249267578125,-41.59672927856445,-10.13178539276123,22.89114761352539,-0.7267637848854065,-28.007591247558594,-2.1630730628967285,20.652097702026367,25.00341796875,22.235034942626953,32.63166809082031,26.395931243896484,-7.741590976715088,-18.751144409179688,-10.387016296386719,1.6861021518707275,18.365686416625977,32.808956146240234,-8.020000457763672,31.18318748474121,34.698951721191406,32.297786712646484,11.507431030273438,24.1983585357666,33.140228271484375],\"y\":[-27.562931060791016,6.780995845794678,-27.490121841430664,3.9244651794433594,-27.74836540222168,-27.755922317504883,-3.6617894172668457,-16.762704849243164,11.944828987121582,-14.98711109161377,-13.49716567993164,18.993791580200195,28.258914947509766,26.937591552734375,0.9974827766418457,-31.948129653930664,-25.5972957611084,-6.211214542388916,10.445613861083984,-9.956430435180664,-46.857086181640625,23.515644073486328,23.953411102294922,51.165283203125,-4.87436580657959,-20.34408187866211,-0.09707656502723694,6.934147357940674,54.946998596191406,-30.672163009643555,35.2141227722168,23.058996200561523,17.427936553955078,-16.687950134277344,-23.080215454101562,23.497413635253906,25.168832778930664,14.57544994354248,4.853172779083252,-8.526320457458496,37.368621826171875,34.610469818115234,-26.357561111450195,-44.073585510253906,-0.745458722114563,1.6169707775115967,15.275045394897461,-12.063931465148926,17.66379165649414,5.083569526672363,23.711444854736328,17.57640266418457,26.609962463378906,34.45457077026367,1.61262845993042,4.46609354019165,26.664806365966797,-50.37608337402344,-13.643120765686035,27.498065948486328,9.332266807556152,19.83056640625,57.06903076171875,10.641283988952637,33.955692291259766,-6.4652180671691895,26.662155151367188,28.988454818725586,-1.139563798904419,19.8980770111084,19.182931900024414,22.548633575439453,-4.1661481857299805,26.48397445678711,7.251826286315918,-7.993980884552002,-11.492693901062012,36.324790954589844,52.2351188659668,20.445369720458984,-45.135093688964844,-4.167784214019775,26.155672073364258,-0.017225047573447227,19.524972915649414,51.8110237121582,12.66495418548584,14.208826065063477,-1.3252557516098022,5.749322414398193,-24.682886123657227,52.90196228027344,-16.63422393798828,29.33689308166504,20.102462768554688,3.817323684692383,9.221240043640137,28.94686508178711,17.529226303100586,5.556171417236328,33.42033004760742,14.136598587036133,-9.979663848876953,16.917695999145508,24.775062561035156,43.18125534057617,15.545509338378906,26.718460083007812,16.531375885009766,5.09115743637085,12.020403861999512,21.202022552490234,6.544589519500732,19.891170501708984,39.185970306396484,24.544597625732422,24.049301147460938,21.816125869750977,-19.855104446411133,23.963293075561523,52.87493133544922,35.51734924316406,5.539718151092529,27.611148834228516,20.570728302001953,52.59550476074219,1.3679620027542114,55.07463836669922,16.404483795166016,32.65922546386719,-5.072752475738525,-10.290035247802734,30.206058502197266,34.51570510864258,30.279001235961914,13.955558776855469,16.792490005493164,16.877704620361328,-5.276773452758789,4.51885986328125,-33.92707824707031,-58.69407653808594,19.786130905151367,39.77888107299805,-30.53139305114746,-15.998185157775879,49.300743103027344,22.721057891845703,20.20577049255371,54.263206481933594,45.1395149230957,-45.05897903442383,1.8149681091308594,10.615509986877441,28.565786361694336,14.427054405212402,12.802743911743164,38.94199752807617,19.280309677124023,-24.577150344848633,50.56941223144531,14.576714515686035,27.259601593017578,21.55724334716797,12.858683586120605,23.74685287475586,-7.06909704208374,6.7385101318359375,24.173206329345703,43.04130935668945,18.210620880126953,1.58307945728302,-0.5999966263771057,13.385331153869629,38.14396667480469,-23.747907638549805,-3.621079206466675,-40.88092803955078,28.24103355407715,58.327213287353516,-13.783110618591309,-30.479984283447266,-22.502836227416992,22.458351135253906,26.716445922851562,-21.304664611816406,38.003089904785156,39.78155517578125,35.774051666259766,1.1142127513885498,18.407638549804688,43.03508758544922,40.51326370239258,25.373035430908203,15.98315715789795,3.621863842010498,-31.09604835510254,15.63568115234375,23.217628479003906,-9.462519645690918],\"z\":[-29.04141616821289,-14.853090286254883,-28.649688720703125,-17.351791381835938,-29.97037696838379,-29.521718978881836,5.8136515617370605,-12.034568786621094,-33.94585418701172,-10.839078903198242,-12.0938081741333,19.129737854003906,-38.504825592041016,-34.1279296875,-3.2683334350585938,13.76567268371582,21.42840576171875,-28.358644485473633,8.013935089111328,-24.01861000061035,-1.6001158952713013,-16.85555076599121,-4.9164204597473145,-21.754934310913086,-6.086943626403809,-53.76586151123047,-9.3881254196167,-9.824915885925293,-19.012845993041992,-13.444937705993652,-36.31692886352539,-24.817110061645508,-18.349138259887695,-40.282535552978516,19.761808395385742,-40.061279296875,-15.795624732971191,12.178884506225586,-5.417938709259033,-34.48660659790039,-18.477079391479492,-23.56647300720215,-7.484415531158447,11.214950561523438,-9.425414085388184,-7.24263858795166,-29.15167236328125,-13.72746467590332,-15.812132835388184,25.686559677124023,-22.629905700683594,20.753009796142578,-26.688125610351562,-13.91206169128418,14.292594909667969,-15.51109504699707,4.060978412628174,19.841962814331055,1.9216656684875488,32.97151184082031,-7.665069103240967,-17.65825843811035,-23.67559051513672,-19.939342498779297,-22.792556762695312,5.0326995849609375,29.794981002807617,-36.70448684692383,9.253171920776367,-29.15350341796875,-23.33311653137207,-20.482816696166992,-48.18971252441406,-20.107833862304688,-28.044076919555664,-7.780697345733643,-20.668556213378906,-28.906539916992188,-0.5590263605117798,-25.765913009643555,-13.864233016967773,-26.341238021850586,-0.8512093424797058,-4.068701267242432,-13.761281967163086,23.919788360595703,-38.19257736206055,-21.558937072753906,-42.87678909301758,-12.506499290466309,-6.226319313049316,11.079858779907227,-35.74760818481445,3.8519394397735596,-15.580293655395508,-15.438668251037598,20.84200668334961,-39.97269058227539,-13.282855987548828,5.805530071258545,19.415767669677734,-56.81719970703125,-47.16653823852539,-35.47822189331055,-35.88993453979492,-11.053154945373535,-10.311945915222168,-11.84399700164795,-23.829374313354492,-42.720272064208984,-51.11368179321289,12.827055931091309,1.1416505575180054,40.47548294067383,-24.992206573486328,-2.2982840538024902,-28.4213924407959,1.1466256380081177,16.62898063659668,-42.410491943359375,4.64854621887207,-44.09934997558594,-35.90857696533203,-24.55974006652832,-19.340505599975586,-18.837581634521484,53.3907585144043,-17.782154083251953,-8.033329010009766,-16.165380477905273,11.479872703552246,-29.949743270874023,-15.857528686523438,-17.5401611328125,-2.0816829204559326,-9.732161521911621,-27.585603713989258,-13.96479320526123,-38.63801193237305,-15.981067657470703,-11.603229522705078,2.674657106399536,-1.1013202667236328,-9.334364891052246,-28.837291717529297,-9.759879112243652,4.552979946136475,-33.086795806884766,30.548412322998047,5.2769598960876465,-17.68069839477539,-9.723531723022461,-32.0234260559082,-20.667945861816406,-17.098909378051758,-27.672649383544922,-12.252344131469727,3.2919678688049316,-0.07474692165851593,-23.481651306152344,16.05228042602539,38.33932876586914,15.838435173034668,-1.3923205137252808,-36.39277267456055,-25.14854621887207,-41.52500915527344,-14.881072044372559,-40.283870697021484,-9.885761260986328,-6.7974534034729,35.864383697509766,-35.86029052734375,-10.165631294250488,9.696345329284668,-10.234956741333008,-19.341691970825195,-13.532757759094238,-19.472414016723633,-19.9440975189209,-10.719045639038086,-4.814250469207764,18.2781982421875,-12.384478569030762,-22.841102600097656,-14.616059303283691,-16.578989028930664,1.2986674308776855,7.653756618499756,-21.702489852905273,-36.69131851196289,-14.513721466064453,-16.959928512573242,-52.73189163208008,-12.97304916381836,3.5051419734954834,-5.6458821296691895,-24.283967971801758,-25.47785758972168,-49.10447311401367],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('27b8f9af-19a5-48d4-a1c6-da153bef2aea');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusiones finales\n",
        "\n",
        "- Relaciones semánticas: Los resultados de los ensayos muestran que los embeddings generados son capaces de capturar relaciones semánticas relevantes entre las palabras. Los términos más relacionados con cada palabra clave (como \"actor,\" \"plot,\" o \"soundtrack\") corresponden a sinónimos, roles específicos, o conceptos cercanos en el contexto del cine, lo que indica que los embeddings son efectivos para representar la similitud semántica en el dominio del análisis de películas.\n",
        "\n",
        "- Diferenciación de conceptos: Las palabras menos relacionadas, como \"studio\" con \"excellent\" o \"animals\" con \"actor,\" reflejan conceptos que están fuera del contexto inmediato de los términos clave. Esto sugiere que los embeddings también son efectivos en la diferenciación de conceptos que no comparten un vínculo semántico directo.\n",
        "\n",
        "- Visualización en 2D y 3D: La visualización de los embeddings en 2D y 3D proporciona una representación de cómo las palabras se agrupan según su similitud semántica. Los términos que son más similares tienden a agruparse juntos, mientras que los menos relacionados están más dispersos. Estas visualizaciones ayudan a entender mejor la estructura del espacio de embeddings y cómo se representan las relaciones entre palabras.\n",
        "\n",
        "- Aplicación potencial: Los resultados obtenidos son útiles para tareas como la clasificación de texto y el análisis de sentimientos en el contexto de reseñas de películas. Estos ensayos demuestran que los embeddings pueden ser una herramienta poderosa para comprender y manipular el lenguaje natural en aplicaciones prácticas."
      ],
      "metadata": {
        "id": "wuucECyOWsxB"
      }
    }
  ]
}